{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSgOxxDlYBLV"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "w8DDvU6ZYhyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open an image (change 'logo.jpg' to your actual file)\n",
        "from PIL import Image\n",
        "image_path = \"logo1.jpg\"\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Ask Gemini to recognize the brand/logo\n",
        "model =genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"Identify the brand or company associated with this logo.\", image])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "gsMdcJjkaNVt",
        "outputId": "0408af0e-8f36-411c-ba70-c9582c347155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for **Amazon**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"product.jpg\"\n",
        "image = Image.open(image_path)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"What product is shown in this image?\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "3QX9LAsVdREV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1a97340-7f6e-437c-ebc1-3121f5de05c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "76EG2r2lj2M4",
        "outputId": "8baa80c2-3b72-4c48-e24c-4b7783d37c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the pictured black over-ear headphones:\n",
            "\n",
            "To give you the best recommendations, I need more information about what aspects of the headphones are important to you.  However, I can offer some general suggestions based on the image:\n",
            "\n",
            "**Similar in Style and Features:**\n",
            "\n",
            "* **Other over-ear, closed-back headphones:** Look for headphones with a similar design, focusing on closed-back models (meaning the earcups fully enclose your ears, blocking out external noise). Brands like Sony, Bose, Sennheiser, Audio-Technica, and AKG offer many options in this style.  Pay attention to features like noise cancellation (if desired) and wireless connectivity (Bluetooth).\n",
            "\n",
            "**Factors to Consider When Choosing a Similar Product:**\n",
            "\n",
            "* **Budget:** Prices for over-ear headphones vary drastically.\n",
            "* **Noise cancellation:**  Do you need active noise cancellation (ANC) to block out surrounding sounds?\n",
            "* **Wireless or wired:** Do you prefer the convenience of wireless Bluetooth headphones or the reliability of a wired connection?\n",
            "* **Sound quality:**  Look for reviews that mention bass response, clarity, and overall sound signature.\n",
            "* **Comfort:**  Consider the size and weight of the headphones, and whether they have comfortable earpads and a headband.\n",
            "* **Microphone:** If you plan to use them for calls, ensure they have a good microphone.\n",
            "\n",
            "\n",
            "To find the best alternatives, I suggest searching online retailers like Amazon, Best Buy, or directly on the websites of the brands mentioned above.  Use keywords like \"closed-back over-ear headphones,\" \"wireless over-ear headphones,\" or \"noise-canceling over-ear headphones,\" along with your desired budget and other features.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open an image containing a price\n",
        "image_path = \"invoice.jpg\"  # Change to your image file\n",
        "image = Image.open(image_path)\n",
        "# Ask Gemini AI to extract the price\n",
        "response = model.generate_content([\"Extract the price from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "UOhLLV15kMWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31b2cd87-926e-455c-8dc4-a739864d2c92"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of each item is $10.00.  The subtotal is $100.00, with a 10% tax, resulting in a grand total of $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Extract the price, currency, and any discounts from this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "JmENj9qwSaLx",
        "outputId": "734cfa16-15d3-4a17-bf1d-35d7c6daaac1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the provided invoice image:\n",
            "\n",
            "* **Price:** $10.00 (per item)\n",
            "* **Currency:** USD ($)\n",
            "* **Discounts:** No discounts are listed.  There is a 10% tax, but that's not a discount.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open an image containing a price\n",
        "image_path = \"bicycle.jpg\"  # Change to your image file\n",
        "image = Image.open(image_path)\n",
        "# Ask Gemini AI to extract the price\n",
        "response = model.generate_content([\"Identify all objects present in this image.\", image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "r2aEju7bSgSH",
        "outputId": "b92956f0-8519-4a53-9a63-a390e149b436"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of the objects present in the image:\n",
            "\n",
            "* **Two bicycles:** One is mostly yellow and black, the other is white.\n",
            "* **Two men:** Riding the bicycles. One is wearing a blue shirt and camouflage shorts; the other is wearing a grey long-sleeved shirt, blue jeans, and a red cap.\n",
            "* **A motorcycle:** Parked on the left side of the image.\n",
            "* **A man:** Sitting inside a building in the background.\n",
            "* **A building:** Showing a storefront with a roll-up door and windows.\n",
            "* **Chairs:** Two chairs are visible inside the building.\n",
            "* **Street:** Wet, indicating recent rain.\n",
            "* **Vegetation:** Some grass is visible along the side of the street.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(\"items.jpg\")\n",
        "response = model.generate_content([\"List all objects in this image and count how many of each are present.\", image])\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "waExV0b1TgSz",
        "outputId": "3834d3ec-1743-4bcf-e7bf-2f082cd8ca5e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of the objects in the image and their counts:\n",
            "\n",
            "**Countables:**\n",
            "\n",
            "* Eggs: 3\n",
            "* Banana: 1\n",
            "* Olive: 2\n",
            "* Fries: 1 (portion)\n",
            "* Burger: 1\n",
            "* Hot dog: 1\n",
            "* Apple: 1\n",
            "* Carrots: 2\n",
            "* Tomatoes: 3\n",
            "* Watermelon: 1\n",
            "\n",
            "\n",
            "**Uncountables:**\n",
            "\n",
            "* Milk: 1 (bottle)\n",
            "* Flour: 1 (bag)\n",
            "* Salt: 1 (container)\n",
            "* Sugar: 1 (bowl)\n",
            "* Jam: 1 (jar)\n",
            "* Meat: 2 (slices)\n",
            "* Rice: 1 (bowl)\n",
            "* Honey: 1 (jar)\n",
            "* Tea: 1 (cup)\n",
            "* Cheese: 1 (slice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4UdTO1eUZhg",
        "outputId": "8e35a2ca-f6d1-47d7-e1b9-c41f8d9a4928"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, youtube-transcript-api\n",
            "Successfully installed pytube-15.0.0 youtube-transcript-api-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "def get_youtube_transcript(video_url):\n",
        "    \"\"\"Fetches the transcript of a YouTube video.\"\"\"\n",
        "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]  # Extract video ID\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
        "    return full_text\n",
        "# Example Usage\n",
        "video_url = \"https://www.youtube.com/watch?v=unYDoA8QGH0&list=PLWEpztHwA4ZT2QlHC74oIz4MsawcvE-QX\"\n",
        "video_transcript = get_youtube_transcript(video_url)\n",
        "print(\"Transcript:\\n\", video_transcript[:500])  # Show first 500 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwQp2oA_UuuY",
        "outputId": "6021e7fb-a993-4ac2-ffd3-9b509c7bf544"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:\n",
            " hi guys today I'm going to introduce you what is machine learning uh these are my presentation content what is machine learning what are the different applications of machine learning different types of machine learning and how to build a machine learning system or model then various kinds of algorithms and later on in this series we are going to take a Hands-On you know case studies or doing programming for various kinds of up algorithms so what is machine learning so machine learning is nothin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Gemini API\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "1LtbLSCrVexC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "    \"\"\"Summarizes the YouTube video transcript using Gemini AI.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    prompt = f\"Summarize the following YouTube video transcript:\\n\\n{text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "summary = summarize_video(video_transcript)\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "jN3MzpXVWTz4",
        "outputId": "62ccbd14-0d33-4eb6-fa71-aca0c42419e0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " This YouTube video is an introduction to machine learning.  The presenter defines machine learning as learning from data, a subfield of AI that enables smarter applications.  Key concepts covered include:\n",
            "\n",
            "* **What is Machine Learning?**  It's about creating systems that learn from data (training data) to make predictions about future events.  The presenter highlights Arthur Samuel's definition:  giving computers the ability to learn without explicit programming.\n",
            "\n",
            "* **Applications of Machine Learning:**  The video lists numerous applications, including speech recognition (Siri, Google Now), web search engines, recommendation systems, computer vision (image and video analysis), information retrieval (like Google search), and fraud detection.\n",
            "\n",
            "* **Types of Machine Learning:** The video categorizes machine learning into three types:\n",
            "    * **Supervised learning:**  The training data includes labels indicating the desired outcome (e.g., spam/not spam).  This is further divided into classification (predicting categories) and regression (predicting continuous values).\n",
            "    * **Unsupervised learning:** The training data lacks labels; the goal is to discover patterns and structures in the data (e.g., clustering).\n",
            "    * **Reinforcement learning:** An agent learns through trial and error in an environment, receiving rewards or penalties based on its actions (e.g., game playing).\n",
            "\n",
            "* **Building a Machine Learning Model:** The presenter outlines the process, including data pre-processing (cleaning, scaling, encoding, feature selection), algorithm selection (e.g., decision trees, random forests, K-nearest neighbors), model building, and model evaluation.  The importance of building multiple models and comparing their performance is emphasized.\n",
            "\n",
            "The video concludes by promising hands-on case studies and programming examples in future sessions.  It also defines key terms like features, attributes, samples, instances, observations, target variable, and response variable.  The Iris dataset is mentioned as a common example used in machine learning.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_insights(text):\n",
        "\n",
        "    \"\"\"Extracts key insights from the YouTube video transcript.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Extract the key takeaways and insights from this YouTube video:\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "insights = extract_video_insights(video_transcript)\n",
        "print(\"Key Insights:\\n\", insights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SNqVslHUWYVZ",
        "outputId": "f3f0db46-1f44-45a7-941b-453d0d94724f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Insights:\n",
            " This YouTube video provides an introduction to machine learning. Here are the key takeaways and insights:\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "* **Definition:** Machine learning is a subfield of artificial intelligence that allows computers to learn from data without explicit programming.  It involves building models from training data (past experience) to predict future outcomes.  The core idea is learning from experience (data) to improve performance on a specific task.\n",
            "\n",
            "* **Arthur Samuel's Definition:**  A field of study that gives computers the ability to learn without being explicitly programmed.\n",
            "\n",
            "* **Simple Definition:** Learning from data.\n",
            "\n",
            "\n",
            "**Applications of Machine Learning:**\n",
            "\n",
            "The video highlights the broad applicability of machine learning across numerous domains, including:\n",
            "\n",
            "* **Speech Recognition:**  Powering applications like Siri, Alexa, and Google Assistant.\n",
            "* **Web Search:**  Improving search engine results (e.g., using algorithms like Naive Bayes).\n",
            "* **Recommendation Systems:**  Suggesting products or content to users.\n",
            "* **Computer Vision:**  Enabling image and video analysis and understanding.\n",
            "* **Information Retrieval:**  Processing vast amounts of data to deliver relevant information (as seen in Google search).\n",
            "* **Fraud Detection:** Identifying malicious activities online.\n",
            "\n",
            "\n",
            "**Types of Machine Learning:**\n",
            "\n",
            "The video categorizes machine learning into three main types:\n",
            "\n",
            "* **Supervised Learning:** The algorithm learns from labeled data where the desired outcome is known. This is further divided into:\n",
            "    * **Classification:** Predicting a categorical outcome (e.g., spam/not spam, digit recognition).\n",
            "    * **Regression:** Predicting a continuous outcome (e.g., house price, temperature).\n",
            "\n",
            "* **Unsupervised Learning:** The algorithm learns from unlabeled data, aiming to discover patterns and structure within the data. Examples include clustering (grouping similar data points) and dimensionality reduction (reducing the number of variables).\n",
            "\n",
            "* **Reinforcement Learning:**  An agent learns through trial and error by interacting with an environment.  Actions result in rewards or penalties, guiding the agent to learn optimal behavior.  Games and robotics are common applications.\n",
            "\n",
            "\n",
            "**Building a Machine Learning Model (Workflow):**\n",
            "\n",
            "The video outlines a typical machine learning workflow:\n",
            "\n",
            "1. **Data Preprocessing:** Cleaning and preparing the data (handling missing values, scaling features, encoding categorical variables, feature selection/dimensionality reduction).\n",
            "2. **Algorithm Selection:** Choosing an appropriate algorithm based on the problem type (classification, regression, etc.).\n",
            "3. **Model Building:** Training the model on the prepared data.\n",
            "4. **Model Evaluation:** Assessing the model's performance using metrics like accuracy.  The presenter emphasizes building multiple models and comparing their performance.\n",
            "\n",
            "\n",
            "**Key Terms:**\n",
            "\n",
            "The video defines important terms like:\n",
            "\n",
            "* **Features/Attributes/Measurements/Dimensions:** Columns in a dataset (excluding the target variable).\n",
            "* **Samples/Instances/Observations:** Rows in a dataset.\n",
            "* **Target Variable/Response Variable:** The column to be predicted.\n",
            "\n",
            "\n",
            "**Future Steps:**  The presenter plans to cover practical implementation and specific algorithms in future videos, including hands-on case studies.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "\n",
        "    \"\"\"Performs sentiment analysis on the YouTube video transcript.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Analyze the sentiment of this YouTube video transcript. Is it positive, negative, or neutral?\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "sentiment = analyze_sentiment(video_transcript)\n",
        "\n",
        "print(\"Sentiment Analysis:\\n\", sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "f7_f5ML5XyEU",
        "outputId": "893f97f6-316d-4900-dc71-cc942edd04b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis:\n",
            " The sentiment of the YouTube video transcript is overwhelmingly **positive**.  The presenter displays enthusiasm for the subject of machine learning, consistently using positive language (\"smarter applications,\" \"very good,\" \"growing a lot,\" \"intelligent application\"). The tone is instructional and encouraging, aiming to help the viewer understand and engage with the material. While there's no explicitly positive emotional expression, the overall effect is one of optimistic instruction and excitement about the potential of machine learning.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Qk5M8CJYHlb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}